{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "import einops\n",
    "from einops.layers.torch import Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_params = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtBlock(nn.Module):\n",
    "    '''\n",
    "    Implementation of a ConvNeXt block.\n",
    "    ConvNeXt block is a residual convolutional block with a depthwise spatial convolution and an inverted bottleneck layer.\n",
    "    It is a modern variant of the ResNet block, which is especially efficient for large receptive fields.\n",
    "    '''\n",
    "    def __init__(self, input_channels: int, output_channels: int, kernel_size: int = 7, expansion_factor: int = 4, activation_fn = nn.GELU) -> None:\n",
    "        '''\n",
    "        input_channels: Number of input channels\n",
    "        output_channels: Number of output channels\n",
    "        kernel_size: Kernel size of the depthwise convolution\n",
    "        expansion_factor: Expansion factor of the inverted bottleneck layer\n",
    "        activation_fn: Activation function to use\n",
    "        '''\n",
    "        super().__init__()\n",
    "        dim = input_channels * expansion_factor # Dimension of the inverted bottleneck layer\n",
    "        # The residual block consists of a depthwise convolution, a group normalization, an inverted bottleneck layer and a projection to the output dimension.\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, input_channels, kernel_size = kernel_size, groups = input_channels, padding = 'same'), #Process spatial information per channel\n",
    "            nn.GroupNorm(num_groups= 1, num_channels= input_channels), # Normalize each channel to have mean 0 and std 1, this stabilizes training.\n",
    "            nn.Conv2d(input_channels, dim, kernel_size = 1), # Expand to higher dim\n",
    "            activation_fn(),# Non-linearity\n",
    "            nn.Conv2d(dim, output_channels, kernel_size = 1), # Project back to lower dim\n",
    "        )\n",
    "        # Shortcut connection to downsample residual dimension if needed\n",
    "        self.shortcut = nn.Conv2d(input_channels, output_channels, kernel_size = 1) if input_channels != output_channels else nn.Identity() # Identity if same dim, else 1x1 conv to project to same dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.residual(x) + self.shortcut(x)\n",
    "\n",
    "class Nino_classifier(nn.Module):\n",
    "    '''\n",
    "    Implementation of a ConvNeXt classifier for SST data.\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                input_dim: int = 1, \n",
    "                latent_dim: int = 128,\n",
    "                num_classes: int = 3, \n",
    "                num_layers: int = 4,\n",
    "                downsampling: int = -1,\n",
    "                expansion_factor: int = 4, \n",
    "                kernel_size: int = 7,\n",
    "                activation_fn = nn.GELU):\n",
    "        '''\n",
    "        input_dim: Number of input channels\n",
    "        latent_dim: Number of channels in the latent feature map\n",
    "        num_classes: Number of classes to classify\n",
    "        num_layers: Number of ConvNeXt blocks\n",
    "        downsample_input: Whether to downsample the input with a strided convolution or not\n",
    "        expansion_factor: Expansion factor of the inverted bottleneck layer\n",
    "        kernel_size: Kernel size of the depthwise convolutions\n",
    "        activation_fn: Activation function to use\n",
    "        '''\n",
    "        super().__init__()\n",
    "        #First we need to project the input to the latent dimension\n",
    "        if downsampling > 0: # If we want to downsample the input, we use a strided convolution. This reduces the computational cost of the network a lot.\n",
    "            assert downsampling % 2 == 0, 'Downsampling factor must be even'\n",
    "            self.input_projection = nn.Conv2d(input_dim, latent_dim, kernel_size= kernel_size, stride = downsampling, padding = kernel_size // 2)\n",
    "        else: #If we don't want to downsample the input, we use a 1x1 convolution. This is a cheap operation that doesn't change the spatial dimension.\n",
    "            self.input_projection = nn.Conv2d(input_dim, latent_dim, 1)\n",
    "\n",
    "        #Then we process the spatial information with a series of Residual blocks defined above.\n",
    "        self.cnn_blocks = nn.ModuleList([ConvNeXtBlock(latent_dim, latent_dim, kernel_size, expansion_factor, activation_fn) for _ in range(num_layers)]) # List of convolutional blocks\n",
    "\n",
    "        #Finally, we average the latent feature map and perform classification with an inverted bottleneck MLP.\n",
    "        self.classifier = nn.Sequential(\n",
    "            Reduce('b c h w -> b c', 'mean'), # Global average pooling, I think this is the same as nn.AdaptiveAvgPool2d(1) but more explicit.\n",
    "            nn.Linear(latent_dim, latent_dim * expansion_factor), # Linear layer to expand to higher dim\n",
    "            activation_fn(), # Non-linearity\n",
    "            nn.Linear(latent_dim * expansion_factor, num_classes), # Final classification layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x: th.Tensor) -> th.Tensor:\n",
    "        # x.shape = (batch_size, input_dim, height, width)\n",
    "        x = self.input_projection(x) # (batch_size, latent_dim, height, width)\n",
    "        for block in self.cnn_blocks:\n",
    "            x = block(x)\n",
    "        logits = self.classifier(x) # (batch_size, num_classes)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Nino_classifier().to(device)\n",
    "x = th.randn((64, 1, 64, 160), device = device)\n",
    "y = cnn(x)\n",
    "loss = nn.CrossEntropyLoss()(y, th.randint(0, 3, (64,), device = device))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627459"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
